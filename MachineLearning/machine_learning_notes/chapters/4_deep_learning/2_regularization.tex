\section{Norm penalities}
We denote the regularized objective function by:
\begin{center}
    $\tilde{J}(\bm{\theta}, \bm{X}, \bm{y}) = J(\bm{\theta}, \bm{X}, \bm{y}) =
    \alpha\Omega(\bm{\theta})$ with 
    $\begin{cases}
        \alpha\in[0,\infty[\text{ hyper-parameters weighting the impact of norm 
        penalty}\\
        \Omega\text{ relative to standard objective function }J
    \end{cases}$
\end{center}

\input{chapters/4_deep_learning/2_regularization/1_norm_penalities.tex}


